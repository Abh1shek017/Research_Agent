[
  {
    "title": "Deep Learning in Deterministic Computational Mechanics",
    "summary": "The rapid growth of deep learning research, including within the field of\ncomputational mechanics, has resulted in an extensive and diverse body of\nliterature. To help researchers identify key concepts and promising\nmethodologies within this field, we provide an overview of deep learning in\ndeterministic computational mechanics. Five main categories are identified and\nexplored: simulation substitution, simulation enhancement, discretizations as\nneural networks, generative approaches, and deep reinforcement learning. This\nreview focuses on deep learning methods rather than applications for\ncomputational mechanics, thereby enabling researchers to explore this field\nmore effectively. As such, the review is not necessarily aimed at researchers\nwith extensive knowledge of deep learning -- instead, the primary audience is\nresearchers at the verge of entering this field or those who attempt to gain an\noverview of deep learning in computational mechanics. The discussed concepts\nare, therefore, explained as simple as possible.",
    "pdf_url": "http://arxiv.org/pdf/2309.15421v1",
    "published": "2023-09-27",
    "authors": [
      "Leon Herrmann",
      "Stefan Kollmannsberger"
    ],
    "category": "cs.LG",
    "pdf_path": "papers\\2309.15421v1.pdf",
    "extracted_text": "Deep Learning in Deterministic Computational\nMechanics\nLeon Herrmann\u22171and Stefan Kollmannsberger1\n1Chair of Computational Modeling and Simulation, Technical University of Munich, School of Engineering and\nDesign, Arcisstrae 21, Munich, 80 333, Germany\nAbstract\nThe rapid growth of deep learning research, including within the field of computational mechanics,\nhas resulted in an extensive and diverse body of literature. To help researchers identify key concepts\nand promising methodologies within this field, we provide an overview of deep learning in deter-\nministic computational mechanics. Five main categories are identified and explored: simulation\nsubstitution, simulation enhancement, discretizations as neural networks, generative approaches,\nand deep reinforcement learning. This review focuses on deep learning methods rather than ap-\nplications for computational mechanics, thereby enabling researchers to explore this field more\neffectively. As such, the review is not necessarily aimed ...",
    "analysis": {
      "word_count": 31394,
      "common_terms": [
        [
          "vol",
          448
        ],
        [
          "learning",
          390
        ],
        [
          "neural",
          325
        ],
        [
          "pp",
          270
        ],
        [
          "deep",
          235
        ],
        [
          "networks",
          225
        ],
        [
          "mechanics",
          199
        ],
        [
          "physics",
          192
        ],
        [
          "data",
          178
        ],
        [
          "methods",
          168
        ]
      ],
      "references": 953
    }
  },
  {
    "title": "Residue-based Label Protection Mechanisms in Vertical Logistic Regression",
    "summary": "Federated learning (FL) enables distributed participants to collaboratively\nlearn a global model without revealing their private data to each other.\nRecently, vertical FL, where the participants hold the same set of samples but\nwith different features, has received increased attention. This paper first\npresents one label inference attack method to investigate the potential privacy\nleakages of the vertical logistic regression model. Specifically, we discover\nthat the attacker can utilize the residue variables, which are calculated by\nsolving the system of linear equations constructed by local dataset and the\nreceived decrypted gradients, to infer the privately owned labels. To deal with\nthis, we then propose three protection mechanisms, e.g., additive noise\nmechanism, multiplicative noise mechanism, and hybrid mechanism which leverages\nlocal differential privacy and homomorphic encryption techniques, to prevent\nthe attack and improve the robustness of the vertical logistic regression.\nmodel. Experimental results show that both the additive noise mechanism and the\nmultiplicative noise mechanism can achieve efficient label protection with only\na slight drop in model testing accuracy, furthermore, the hybrid mechanism can\nachieve label protection without any testing accuracy degradation, which\ndemonstrates the effectiveness and efficiency of our protection techniques",
    "pdf_url": "http://arxiv.org/pdf/2205.04166v1",
    "published": "2022-05-09",
    "authors": [
      "Juntao Tan",
      "Lan Zhang",
      "Yang Liu",
      "Anran Li",
      "Ye Wu"
    ],
    "category": "cs.LG",
    "pdf_path": "papers\\2205.04166v1.pdf",
    "extracted_text": "Residue-based Label Protection Mechanisms in\nVertical Logistic Regression\nJuntao Tany, Lan Zhangy, Yang Liuz, Anran Liy, and Ye Wuz\nySchool of Computer Science and Technology, University of Science and Technology of China, Hefei, China\nzByteDance Security Research Department, Bejing, China\nftjt, anranLig@mail.ustc.edu.cn, zhanglan@ustc.edu.cn, fliuyang.fromthu, wuye.2020 g@bytedance.com\nAbstract \u2014Federated learning (FL) enables distributed partic-\nipants to collaboratively learn a global model without revealing\ntheir private data to each other. Recently, vertical FL, where\nthe participants hold the same set of samples but with dif-\nferent features, has received increased attention. This paper\n\ufb01rst presents one label inference attack method to investigate\nthe potential privacy leakages of the vertical logistic regression\nmodel. Speci\ufb01cally, we discover that the attacker can utilize the\nresidue variables, which are calculated by solving the system of\nlinear equations constructed by local...",
    "analysis": {
      "word_count": 6253,
      "common_terms": [
        [
          "model",
          84
        ],
        [
          "privacy",
          48
        ],
        [
          "noise",
          48
        ],
        [
          "alice",
          48
        ],
        [
          "residue",
          45
        ],
        [
          "auc",
          42
        ],
        [
          "accuracy",
          41
        ],
        [
          "mechanism",
          37
        ],
        [
          "training",
          34
        ],
        [
          "bob",
          34
        ]
      ],
      "references": 94
    }
  }
]